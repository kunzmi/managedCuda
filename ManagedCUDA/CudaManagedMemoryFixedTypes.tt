<#@ template debug="false" hostspecific="false" language="C#" #>
<#@ output extension=".cs" #>
<# 
  string[] types = new string[]{"byte", "uchar1", "uchar2", "uchar3", "uchar4",
								"sbyte", "char1", "char2", "char3", "char4",
								"short", "short1", "short2", "short3", "short4",
								"ushort", "ushort1", "ushort2", "ushort3", "ushort4",
								"int", "int1", "int2", "int3", "int4",
								"uint", "uint1", "uint2", "uint3", "uint4",
								"long", "long1", "long2",
								"ulong", "ulong1", "ulong2",
								"float", "float1", "float2", "float3", "float4",
								"double", "double1", "double2",
								"cuDoubleComplex", "cuDoubleReal", "cuFloatComplex", "cuFloatReal",
								"dim3"								
								};
#>
// Copyright (c) 2023, Michael Kunz and Artic Imaging SARL. All rights reserved.
// http://kunzmi.github.io/managedCuda
//
// This file is part of ManagedCuda.
//
// Commercial License Usage
//  Licensees holding valid commercial ManagedCuda licenses may use this
//  file in accordance with the commercial license agreement provided with
//  the Software or, alternatively, in accordance with the terms contained
//  in a written agreement between you and Artic Imaging SARL. For further
//  information contact us at managedcuda@articimaging.eu.
//  
// GNU General Public License Usage
//  Alternatively, this file may be used under the terms of the GNU General
//  Public License as published by the Free Software Foundation, either 
//  version 3 of the License, or (at your option) any later version.
//  
//  ManagedCuda is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
//  GNU General Public License for more details.
//  
//  You should have received a copy of the GNU General Public License
//  along with this program. If not, see <http://www.gnu.org/licenses/>.

using System;
using System.Collections;
using System.Collections.Generic;
using ManagedCuda.BasicTypes;
using ManagedCuda.VectorTypes;
using System.Runtime.InteropServices;
using System.Diagnostics;

namespace ManagedCuda
{
	<# foreach (string type in types) {#>

	/// <summary>
	/// A variable located in managed memory.<para/>
	/// Type: <#=type#>
	/// </summary>
	public unsafe class CudaManagedMemory_<#=type#>: IDisposable, IEnumerable<<#=type#>>
	{
		private CUdeviceptr _devPtr;
		private <#=type#>* _ptr;
		private SizeT _size = 0;
		private SizeT _typeSize = 0;
		private CUResult res;
		private bool disposed;
		private bool _isOwner;

		#region Constructor
		/// <summary>
		/// Creates a new CudaManagedMemory and allocates the memory on host/device.
		/// </summary>
		/// <param name="size">In elements</param>
		/// <param name="attachFlags"></param>
		public CudaManagedMemory_<#=type#>(SizeT size, CUmemAttach_flags attachFlags)
		{
			_devPtr = new CUdeviceptr();
			_size = size;
			_typeSize = (SizeT)Marshal.SizeOf(typeof(<#=type#>));

			res = DriverAPINativeMethods.MemoryManagement.cuMemAllocManaged(ref _devPtr, _typeSize * size, attachFlags);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemAllocManaged", res));
			if (res != CUResult.Success) throw new CudaException(res);
			_ptr = (<#=type#>*) (UIntPtr)_devPtr.Pointer;
			_isOwner = true;
		}

		/// <summary>
		/// Creates a new CudaManagedMemory from definition in cu-file.
		/// </summary>
		/// <param name="module">The module where the variable is defined in.</param>
		/// <param name="name">The variable name as defined in the cu-file.</param>
		public CudaManagedMemory_<#=type#>(CUmodule module, string name)
		{
			_devPtr = new CUdeviceptr();
			SizeT _sizeInBytes = new SizeT();
			res = DriverAPINativeMethods.ModuleManagement.cuModuleGetGlobal_v2(ref _devPtr, ref _sizeInBytes, module, name);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}. Name: {3}, Size (in bytes): {4}", DateTime.Now, "cuModuleGetGlobal_v2", res, name, _sizeInBytes.ToString()));
			if (res != CUResult.Success) throw new CudaException(res);

			_typeSize = (SizeT)Marshal.SizeOf(typeof(<#=type#>));
			_size = _sizeInBytes / _typeSize;

			if (_sizeInBytes != _size * _typeSize)
				throw new CudaException("Variable size is not a multiple of its type size.");

			_ptr = (<#=type#>*) (UIntPtr)_devPtr.Pointer;
			_isOwner = false;
		}

		/// <summary>
		/// Creates a new CudaManagedMemory from definition in cu-file.
		/// </summary>
		/// <param name="kernel">The kernel which module defines the variable.</param>
		/// <param name="name">The variable name as defined in the cu-file.</param>
		public CudaManagedMemory_<#=type#>(CudaKernel kernel, string name)
			: this(kernel.CUModule, name)
		{
			
		}

		/// <summary>
		/// Creates a new CudaManagedMemory from definition in cu-file.
		/// </summary>
		/// <param name="library">The library where the variable is defined in.</param>
		/// <param name="name">The variable name as defined in the cu-file.</param>
		public CudaManagedMemory_<#=type#>(CUlibrary library, string name)
		{
			_devPtr = new CUdeviceptr();
			SizeT _sizeInBytes = new SizeT();
            res = DriverAPINativeMethods.LibraryManagement.cuLibraryGetManaged(ref _devPtr, ref _sizeInBytes, library, name);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}. Name: {3}, Size (in bytes): {4}", DateTime.Now, "cuLibraryGetManaged", res, name, _sizeInBytes.ToString()));
			if (res != CUResult.Success) throw new CudaException(res);

			_typeSize = (SizeT)Marshal.SizeOf(typeof(<#=type#>));
			_size = _sizeInBytes / _typeSize;

			if (_sizeInBytes != _size * _typeSize)
				throw new CudaException("Variable size is not a multiple of its type size.");

			_ptr = (<#=type#>*) (UIntPtr)_devPtr.Pointer;
			_isOwner = false;
		}

		/// <summary>
		/// Creates a new CudaManagedMemory from definition in cu-file.
		/// </summary>
		/// <param name="library">The library that defines the variable.</param>
		/// <param name="name">The variable name as defined in the cu-file.</param>
		public CudaManagedMemory_<#=type#>(CudaLibrary library, string name)
			: this(library.Library, name)
		{
			
		}

		/// <summary>
		/// For dispose
		/// </summary>
		~CudaManagedMemory_<#=type#>()
		{
			Dispose(false);
		}
		#endregion

		#region Dispose
		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			Dispose(true);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// For IDisposable
		/// </summary>
		/// <param name="fDisposing"></param>
		protected virtual void Dispose(bool fDisposing)
		{
			if (fDisposing && !disposed)
			{
				if (_isOwner)
				{
					res = DriverAPINativeMethods.MemoryManagement.cuMemFree_v2(_devPtr);
					Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemFree_v2", res));
				}
				disposed = true;
			}
			if (!fDisposing && !disposed)
				Debug.WriteLine(String.Format("ManagedCUDA not-disposed warning: {0}", this.GetType()));
		}
		#endregion

		#region Properties
		/// <summary>
		/// UIntPtr to managed memory.
		/// </summary>
		public UIntPtr HostPointer
		{
			get { return _devPtr.Pointer; }
		}

		/// <summary>
		/// CUdeviceptr to managed memory.
		/// </summary>
		public CUdeviceptr DevicePointer
		{
			get { return _devPtr; }
		}

		/// <summary>
		/// Size in bytes
		/// </summary>
		public SizeT SizeInBytes
		{
			get { return _size * _typeSize; }
		}

		/// <summary>
		/// Size in elements
		/// </summary>
		public SizeT Size
		{
			get { return _size; }
		}

		/// <summary>
		/// Access array per element.
		/// </summary>
		/// <param name="index">index in elements</param>
		/// <returns></returns>
		public <#=type#> this[SizeT index]
		{
			get
			{
				return _ptr[index];
			}
			set
			{
				_ptr[index] = value;
			}
		}

		/// <summary>
		/// If the wrapper class instance is the owner of a CUDA handle, it will be destroyed while disposing.
		/// </summary>
		public bool IsOwner
		{
			get { return _isOwner; }
		}
		#endregion

		#region Converter operators
		/// <summary>
		/// Converts a managed variable to a host value. In case of multiple managed values (array), only the first value is converted.
		/// </summary>
		/// <param name="d">managed variable</param>
		/// <returns>newly allocated host variable with value from managed memory</returns>
		public static implicit operator <#=type#>(CudaManagedMemory_<#=type#> d)
		{
			return d[0];
		}
		#endregion

		#region GetAttributeMethods
		/// <summary>
		/// The <see cref="CUcontext"/> on which a pointer was allocated or registered
		/// </summary>
		public CUcontext AttributeContext
		{
			get 
			{
				CUcontext ret = new CUcontext();
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.Context, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret;
			}
		}

		/// <summary>
		/// The <see cref="CUMemoryType"/> describing the physical location of a pointer 
		/// </summary>
		public CUMemoryType AttributeMemoryType
		{
			get
			{
				CUMemoryType ret = new CUMemoryType();
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.MemoryType, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret;
			}
		}

		/// <summary>
		/// The address at which a pointer's memory may be accessed on the device <para/>
		/// Except in the exceptional disjoint addressing cases, the value returned will equal the input value.
		/// </summary>
		public CUdeviceptr AttributeDevicePointer
		{
			get
			{
				CUdeviceptr ret = new CUdeviceptr();
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.DevicePointer, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret;
			}
		}

		/// <summary>
		/// The address at which a pointer's memory may be accessed on the host 
		/// </summary>
		public IntPtr AttributeHostPointer
		{
			get
			{
				IntPtr ret = new IntPtr();
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.HostPointer, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret;
			}
		}

		/// <summary>
		/// A pair of tokens for use with the nv-p2p.h Linux kernel interface
		/// </summary>
		public CudaPointerAttributeP2PTokens AttributeP2PTokens
		{
			get
			{
				CudaPointerAttributeP2PTokens ret = new CudaPointerAttributeP2PTokens();
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.P2PTokens, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret;
			}
		}

		/// <summary>
		/// Synchronize every synchronous memory operation initiated on this region
		/// </summary>
		public bool AttributeSyncMemops
		{
			get
			{
				int ret = 0;
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.SyncMemops, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret != 0;
			}
			set 
			{
				int val = value ? 1 : 0;
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerSetAttribute(ref val, CUPointerAttribute.SyncMemops, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerSetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
			}
		}

		/// <summary>
		/// A process-wide unique ID for an allocated memory region
		/// </summary>
		public ulong AttributeBufferID
		{
			get
			{
				ulong ret = 0;
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.BufferID, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret;
			}
		}

		/// <summary>
		/// Indicates if the pointer points to managed memory
		/// </summary>
		public bool AttributeIsManaged
		{
			get
			{
				int ret = 0;
				CUResult res = DriverAPINativeMethods.MemoryManagement.cuPointerGetAttribute(ref ret, CUPointerAttribute.IsManaged, _devPtr);
				Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuPointerGetAttribute", res));
				if (res != CUResult.Success) throw new CudaException(res);
				return ret != 0;
			}
		}
		#endregion

		#region Methods
		/// <summary>
		/// Attach memory to a stream asynchronously
		/// <para/>
		/// Enqueues an operation in <c>hStream</c> to specify stream association of
		/// <c>length</c> bytes of memory starting from <c>dptr</c>. This function is a
		/// stream-ordered operation, meaning that it is dependent on, and will
		/// only take effect when, previous work in stream has completed. Any
		/// previous association is automatically replaced.
		/// <para/>
		/// <c>dptr</c> must point to an address within managed memory space declared
		/// using the __managed__ keyword or allocated with cuMemAllocManaged.
		/// <para/>
		/// <c>length</c> must be zero, to indicate that the entire allocation's
		/// stream association is being changed. Currently, it's not possible
		/// to change stream association for a portion of an allocation.
		/// <para/>
		/// The stream association is specified using <c>flags</c> which must be
		/// one of <see cref="CUmemAttach_flags"/>.
		/// If the <see cref="CUmemAttach_flags.Global"/> flag is specified, the memory can be accessed
		/// by any stream on any device.
		/// If the <see cref="CUmemAttach_flags.Host"/> flag is specified, the program makes a guarantee
		/// that it won't access the memory on the device from any stream.
		/// If the <see cref="CUmemAttach_flags.Single"/> flag is specified, the program makes a guarantee
		/// that it will only access the memory on the device from <c>hStream</c>. It is illegal
		/// to attach singly to the NULL stream, because the NULL stream is a virtual global
		/// stream and not a specific stream. An error will be returned in this case.
		/// <para/>
		/// When memory is associated with a single stream, the Unified Memory system will
		/// allow CPU access to this memory region so long as all operations in <c>hStream</c>
		/// have completed, regardless of whether other streams are active. In effect,
		/// this constrains exclusive ownership of the managed memory region by
		/// an active GPU to per-stream activity instead of whole-GPU activity.
		/// <para/>
		/// Accessing memory on the device from streams that are not associated with
		/// it will produce undefined results. No error checking is performed by the
		/// Unified Memory system to ensure that kernels launched into other streams
		/// do not access this region. 
		/// <para/>
		/// It is a program's responsibility to order calls to <see cref="DriverAPINativeMethods.Streams.cuStreamAttachMemAsync"/>
		/// via events, synchronization or other means to ensure legal access to memory
		/// at all times. Data visibility and coherency will be changed appropriately
		/// for all kernels which follow a stream-association change.
		/// <para/>
		/// If <c>hStream</c> is destroyed while data is associated with it, the association is
		/// removed and the association reverts to the default visibility of the allocation
		/// as specified at cuMemAllocManaged. For __managed__ variables, the default
		/// association is always <see cref="CUmemAttach_flags.Global"/>. Note that destroying a stream is an
		/// asynchronous operation, and as a result, the change to default association won't
		/// happen until all work in the stream has completed.
		/// <para/>
		/// </summary>
		/// <param name="hStream">Stream in which to enqueue the attach operation</param>
		/// <param name="length">Length of memory (must be zero)</param>
		/// <param name="flags">Must be one of <see cref="CUmemAttach_flags"/></param>
		/// <returns></returns>
		public void StreamAttachMemAsync(CUstream hStream, SizeT length, CUmemAttach_flags flags)
		{
			if (disposed) throw new ObjectDisposedException(this.ToString());
			res = DriverAPINativeMethods.Streams.cuStreamAttachMemAsync(hStream, _devPtr, length, flags);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuStreamAttachMemAsync", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}


		/// <summary>
		/// Prefetches memory to the specified destination device<para/>
		/// Prefetches memory to the specified destination device. devPtr is the 
		/// base device pointer of the memory to be prefetched and dstDevice is the 
		/// destination device. count specifies the number of bytes to copy. hStream
		/// is the stream in which the operation is enqueued.<para/>
		/// 
		/// Passing in CU_DEVICE_CPU for dstDevice will prefetch the data to CPU memory.<para/>
		/// 
		/// If no physical memory has been allocated for this region, then this memory region
		/// will be populated and mapped on the destination device. If there's insufficient
		/// memory to prefetch the desired region, the Unified Memory driver may evict pages
		/// belonging to other memory regions to make room. If there's no memory that can be
		/// evicted, then the Unified Memory driver will prefetch less than what was requested.<para/>
		/// 
		/// In the normal case, any mappings to the previous location of the migrated pages are
		/// removed and mappings for the new location are only setup on the dstDevice.
		/// The application can exercise finer control on these mappings using ::cudaMemAdvise.
		/// </summary>
		/// <param name="dstDevice">Destination device to prefetch to</param>
		/// <param name="hStream">Stream to enqueue prefetch operation</param>
		/// <remarks>Note that this function is asynchronous with respect to the host and all work on other devices.</remarks>
		public void PrefetchAsync(CUdevice dstDevice, CUstream hStream)
		{
			if (disposed) throw new ObjectDisposedException(this.ToString());
			res = DriverAPINativeMethods.MemoryManagement.cuMemPrefetchAsync(_devPtr, _size * _typeSize, dstDevice, hStream);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemPrefetchAsync", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}
		

        /// <summary>
        /// Prefetches memory to the specified destination location
        /// Prefetches memory to the specified destination location.  \p devPtr is the
        /// base device pointer of the memory to be prefetched and \p location specifies the
        /// destination location. \p count specifies the number of bytes to copy. \p hStream
        /// is the stream in which the operation is enqueued.The memory range must refer
        /// to managed memory allocated via ::cuMemAllocManaged or declared via __managed__ variables.
        /// 
        /// Specifying::CU_MEM_LOCATION_TYPE_DEVICE for ::CUmemLocation::type will prefetch memory to GPU
        /// specified by device ordinal ::CUmemLocation::id which must have non-zero value for the device attribute
        /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.Additionally, \p hStream must be associated with a device
        /// that has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
        /// 
        /// Specifying ::CU_MEM_LOCATION_TYPE_HOST as ::CUmemLocation::type will prefetch data to host memory.
        /// Applications can request prefetching memory to a specific host NUMA node by specifying
        /// ::CU_MEM_LOCATION_TYPE_HOST_NUMA for ::CUmemLocation::type and a valid host NUMA node id in ::CUmemLocation::id
        /// Users can also request prefetching memory to the host NUMA node closest to the current thread's CPU by specifying
        /// ::CU_MEM_LOCATION_TYPE_HOST_NUMA_CURRENT for ::CUmemLocation::type.Note when ::CUmemLocation::type is etiher
        /// ::CU_MEM_LOCATION_TYPE_HOST OR ::CU_MEM_LOCATION_TYPE_HOST_NUMA_CURRENT, ::CUmemLocation::id will be ignored.
        /// The start address and end address of the memory range will be rounded down and rounded up
        /// respectively to be aligned to CPU page size before the prefetch operation is enqueued
        /// in the stream.
        /// 
        /// If no physical memory has been allocated for this region, then this memory region
        /// will be populated and mapped on the destination device.If there's insufficient
        /// memory to prefetch the desired region, the Unified Memory driver may evict pages from other
        /// ::cuMemAllocManaged allocations to host memory in order to make room. Device memory
        /// allocated using ::cuMemAlloc or::cuArrayCreate will not be evicted.
        /// 
        /// By default, any mappings to the previous location of the migrated pages are removed and
        /// mappings for the new location are only setup on the destination location.The exact behavior however
        /// also depends on the settings applied to this memory range via::cuMemAdvise as described
        /// below:
        /// 
        /// If::CU_MEM_ADVISE_SET_READ_MOSTLY was set on any subset of this memory range,
        /// then that subset will create a read-only copy of the pages on destination location.
        /// If however the destination location is a host NUMA node, then any pages of that subset
        /// that are already in another host NUMA node will be transferred to the destination.
        /// 
        /// If::CU_MEM_ADVISE_SET_PREFERRED_LOCATION was called on any subset of this memory
        /// range, then the pages will be migrated to \p location even if \p location is not the
        /// preferred location of any pages in the memory range.
        /// 
        /// If ::CU_MEM_ADVISE_SET_ACCESSED_BY was called on any subset of this memory range,
        /// then mappings to those pages from all the appropriate processors are updated to
        /// refer to the new location if establishing such a mapping is possible.Otherwise,
        /// those mappings are cleared.
        /// 
        /// Note that this API is not required for functionality and only serves to improve performance
        /// by allowing the application to migrate data to a suitable location before it is accessed.
        /// 
        /// Memory accesses to this range are always coherent and are allowed even when the data is
        /// actively being migrated.
        /// 
        /// </summary>
        /// <param name="location">Destination device to prefetch to</param>
        /// <param name="flags">flags for future use, must be zero now.</param>
        /// <param name="hStream">Stream to enqueue prefetch operation</param>
        /// <remarks>Note that this function is asynchronous with respect to the host and all work on other devices.</remarks>
		public void PrefetchAsync(CUmemLocation location, uint flags, CudaStream hStream)
		{
			if (disposed) throw new ObjectDisposedException(this.ToString());
			res = DriverAPINativeMethods.MemoryManagement.cuMemPrefetchAsync_v2(_devPtr, _size * _typeSize, location, flags, hStream.Stream);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemPrefetchAsync_v2", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}

		#endregion

		#region IEnumerable
		IEnumerator<<#=type#>> IEnumerable<<#=type#>>.GetEnumerator()
		{
			if (disposed) throw new ObjectDisposedException(this.ToString());
			IEnumerator<<#=type#>> enumerator = new CudaManagedMemoryEnumerator_<#=type#>(this);
			return enumerator;
		}

		IEnumerator IEnumerable.GetEnumerator()
		{
			if (disposed) throw new ObjectDisposedException(this.ToString());
			IEnumerator enumerator = new CudaManagedMemoryEnumerator_<#=type#>(this);
			return enumerator;
		}

		#endregion

		#region static methods (new in Cuda 8.0)
		/// <summary>
		/// Advise about the usage of a given memory range<para/>
		/// Advise the Unified Memory subsystem about the usage pattern for the memory range starting at devPtr with a size of count bytes.<para/>
		/// <para/>
		/// The \p advice parameter can take the following values:<para/>
		/// - ::CU_MEM_ADVISE_SET_READ_MOSTLY: This implies that the data is mostly going to be read
		/// from and only occasionally written to. This allows the driver to create read-only
		/// copies of the data in a processor's memory when that processor accesses it. Similarly,
		/// if cuMemPrefetchAsync is called on this region, it will create a read-only copy of
		/// the data on the destination processor. When a processor writes to this data, all copies
		/// of the corresponding page are invalidated except for the one where the write occurred.
		/// The \p device argument is ignored for this advice.<para/>
		/// - ::CU_MEM_ADVISE_UNSET_READ_MOSTLY: Undoes the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY. Any read
		/// duplicated copies of the data will be freed no later than the next write access to that data.<para/>
		/// - ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION: This advice sets the preferred location for the
		/// data to be the memory belonging to \p device. Passing in CU_DEVICE_CPU for \p device sets the
		/// preferred location as CPU memory. Setting the preferred location does not cause data to
		/// migrate to that location immediately. Instead, it guides the migration policy when a fault
		/// occurs on that memory region. If the data is already in its preferred location and the
		/// faulting processor can establish a mapping without requiring the data to be migrated, then
		/// the migration will be avoided. On the other hand, if the data is not in its preferred location
		/// or if a direct mapping cannot be established, then it will be migrated to the processor accessing
		/// it. It is important to note that setting the preferred location does not prevent data prefetching
		/// done using ::cuMemPrefetchAsync.<para/>
		/// Having a preferred location can override the thrash detection and resolution logic in the Unified
		/// Memory driver. Normally, if a page is detected to be constantly thrashing between CPU and GPU
		/// memory say, the page will eventually be pinned to CPU memory by the Unified Memory driver. But
		/// if the preferred location is set as GPU memory, then the page will continue to thrash indefinitely.
		/// When the Unified Memory driver has to evict pages from a certain location on account of that
		/// memory being oversubscribed, the preferred location will be used to decide the destination to which
		/// a page should be evicted to.<para/>
		/// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, the preferred
		/// location will be ignored for that subset.<para/>
		/// - ::CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: Undoes the effect of ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION
		/// and changes the preferred location to none.<para/>
		/// - ::CU_MEM_ADVISE_SET_ACCESSED_BY: This advice implies that the data will be accessed by \p device.
		/// This does not cause data migration and has no impact on the location of the data per se. Instead,
		/// it causes the data to always be mapped in the specified processor's page tables, as long as the
		/// location of the data permits a mapping to be established. If the data gets migrated for any reason,
		/// the mappings are updated accordingly.<para/>
		/// This advice is useful in scenarios where data locality is not important, but avoiding faults is.
		/// Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the
		/// data located on one GPU is occasionally accessed by other GPUs. In such scenarios, migrating data
		/// over to the other GPUs is not as important because the accesses are infrequent and the overhead of
		/// migration may be too high. But preventing faults can still help improve performance, and so having
		/// a mapping set up in advance is useful. Note that on CPU access of this data, the data may be migrated
		/// to CPU memory because the CPU typically cannot access GPU memory directly. Any GPU that had the
		/// ::CU_MEM_ADVISE_SET_ACCESSED_BY flag set for this data will now have its mapping updated to point to the
		/// page in CPU memory.<para/>
		/// - ::CU_MEM_ADVISE_UNSET_ACCESSED_BY: Undoes the effect of CU_MEM_ADVISE_SET_ACCESSED_BY. The current set of
		/// mappings may be removed at any time causing accesses to result in page faults.
		/// <para/>
		/// Passing in ::CU_DEVICE_CPU for \p device will set the advice for the CPU.
		/// <para/>
		/// Note that this function is asynchronous with respect to the host and all work
		/// on other devices.
		/// </summary>
		/// <param name="devPtr">Pointer to memory to set the advice for</param>
		/// <param name="count">Size in bytes of the memory range</param>
		/// <param name="advice">Advice to be applied for the specified memory range</param>
		/// <param name="device">Device to apply the advice for</param>
		public static void MemAdvise(CUdeviceptr devPtr, SizeT count, CUmemAdvise advice, CUdevice device)
		{
			CUResult res = DriverAPINativeMethods.MemoryManagement.cuMemAdvise(devPtr, count, advice, device);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemAdvise", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}

		/// <summary>
		/// Advise about the usage of a given memory range<para/>
		/// Advise the Unified Memory subsystem about the usage pattern for the memory range starting at devPtr with a size of count bytes.<para/>
		/// <para/>
		/// The \p advice parameter can take the following values:<para/>
		/// - ::CU_MEM_ADVISE_SET_READ_MOSTLY: This implies that the data is mostly going to be read
		/// from and only occasionally written to. This allows the driver to create read-only
		/// copies of the data in a processor's memory when that processor accesses it. Similarly,
		/// if cuMemPrefetchAsync is called on this region, it will create a read-only copy of
		/// the data on the destination processor. When a processor writes to this data, all copies
		/// of the corresponding page are invalidated except for the one where the write occurred.
		/// The \p device argument is ignored for this advice.<para/>
		/// - ::CU_MEM_ADVISE_UNSET_READ_MOSTLY: Undoes the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY. Any read
		/// duplicated copies of the data will be freed no later than the next write access to that data.<para/>
		/// - ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION: This advice sets the preferred location for the
		/// data to be the memory belonging to \p device. Passing in CU_DEVICE_CPU for \p device sets the
		/// preferred location as CPU memory. Setting the preferred location does not cause data to
		/// migrate to that location immediately. Instead, it guides the migration policy when a fault
		/// occurs on that memory region. If the data is already in its preferred location and the
		/// faulting processor can establish a mapping without requiring the data to be migrated, then
		/// the migration will be avoided. On the other hand, if the data is not in its preferred location
		/// or if a direct mapping cannot be established, then it will be migrated to the processor accessing
		/// it. It is important to note that setting the preferred location does not prevent data prefetching
		/// done using ::cuMemPrefetchAsync.<para/>
		/// Having a preferred location can override the thrash detection and resolution logic in the Unified
		/// Memory driver. Normally, if a page is detected to be constantly thrashing between CPU and GPU
		/// memory say, the page will eventually be pinned to CPU memory by the Unified Memory driver. But
		/// if the preferred location is set as GPU memory, then the page will continue to thrash indefinitely.
		/// When the Unified Memory driver has to evict pages from a certain location on account of that
		/// memory being oversubscribed, the preferred location will be used to decide the destination to which
		/// a page should be evicted to.<para/>
		/// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, the preferred
		/// location will be ignored for that subset.<para/>
		/// - ::CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: Undoes the effect of ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION
		/// and changes the preferred location to none.<para/>
		/// - ::CU_MEM_ADVISE_SET_ACCESSED_BY: This advice implies that the data will be accessed by \p device.
		/// This does not cause data migration and has no impact on the location of the data per se. Instead,
		/// it causes the data to always be mapped in the specified processor's page tables, as long as the
		/// location of the data permits a mapping to be established. If the data gets migrated for any reason,
		/// the mappings are updated accordingly.<para/>
		/// This advice is useful in scenarios where data locality is not important, but avoiding faults is.
		/// Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the
		/// data located on one GPU is occasionally accessed by other GPUs. In such scenarios, migrating data
		/// over to the other GPUs is not as important because the accesses are infrequent and the overhead of
		/// migration may be too high. But preventing faults can still help improve performance, and so having
		/// a mapping set up in advance is useful. Note that on CPU access of this data, the data may be migrated
		/// to CPU memory because the CPU typically cannot access GPU memory directly. Any GPU that had the
		/// ::CU_MEM_ADVISE_SET_ACCESSED_BY flag set for this data will now have its mapping updated to point to the
		/// page in CPU memory.<para/>
		/// - ::CU_MEM_ADVISE_UNSET_ACCESSED_BY: Undoes the effect of CU_MEM_ADVISE_SET_ACCESSED_BY. The current set of
		/// mappings may be removed at any time causing accesses to result in page faults.
		/// <para/>
		/// Passing in ::CU_DEVICE_CPU for \p device will set the advice for the CPU.
		/// <para/>
		/// Note that this function is asynchronous with respect to the host and all work
		/// on other devices.
		/// </summary>
		/// <param name="ptr">managed memory variable</param>
		/// <param name="advice">Advice to be applied for the specified memory range</param>
		/// <param name="device">Device to apply the advice for</param>
		public static void MemAdvise(CudaManagedMemory_<#=type#> ptr, CUmemAdvise advice, CUdevice device)
		{
			CUResult res = DriverAPINativeMethods.MemoryManagement.cuMemAdvise(ptr.DevicePointer, ptr.SizeInBytes, advice, device);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemAdvise", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}
		#endregion
		
        /// <summary>
        /// Advise about the usage of a given memory range<para/>
        /// Advise the Unified Memory subsystem about the usage pattern for the memory range
        /// starting at \p devPtr with a size of \p count bytes.The start address and end address of the memory
        /// range will be rounded down and rounded up respectively to be aligned to CPU page size before the
        /// advice is applied.The memory range must refer to managed memory allocated via ::cuMemAllocManaged
        /// or declared via __managed__ variables.The memory range could also refer to system-allocated pageable
        /// memory provided it represents a valid, host-accessible region of memory and all additional constraints
        /// imposed by \p advice as outlined below are also satisfied.Specifying an invalid system-allocated pageable
        /// memory range results in an error being returned.
        /// 
        /// The \p advice parameter can take the following values:
        /// - ::CU_MEM_ADVISE_SET_READ_MOSTLY: This implies that the data is mostly going to be read
        /// from and only occasionally written to.Any read accesses from any processor to this region will create a
        /// read-only copy of at least the accessed pages in that processor's memory. Additionally, if ::cuMemPrefetchAsync
        /// or::cuMemPrefetchAsync_v2 is called on this region, it will create a read-only copy of the data on the destination processor.
        /// If the target location for ::cuMemPrefetchAsync_v2 is a host NUMA node and a read-only copy already exists on
        /// another host NUMA node, that copy will be migrated to the targeted host NUMA node.
        /// If any processor writes to this region, all copies of the corresponding page will be invalidated
        /// except for the one where the write occurred. If the writing processor is the CPU and the preferred location of
        /// the page is a host NUMA node, then the page will also be migrated to that host NUMA node. The \p location argument is ignored for this advice.
        /// Note that for a page to be read-duplicated, the accessing processor must either be the CPU or a GPU
        /// that has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
        /// Also, if a context is created on a device that does not have the device attribute
        /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS set, then read-duplication will not occur until
        /// all such contexts are destroyed.
        /// If the memory region refers to valid system-allocated pageable memory, then the accessing device must
        /// have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS for a read-only
        /// copy to be created on that device. Note however that if the accessing device also has a non-zero value for the
        /// device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES, then setting this advice
        /// will not create a read-only copy when that device accesses this memory region.
        /// - ::CU_MEM_ADVISE_UNSET_READ_MOSTLY:  Undoes the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY and also prevents the
        /// Unified Memory driver from attempting heuristic read-duplication on the memory range.Any read-duplicated
        /// copies of the data will be collapsed into a single copy. The location for the collapsed
        /// copy will be the preferred location if the page has a preferred location and one of the read-duplicated
        /// copies was resident at that location.Otherwise, the location chosen is arbitrary.
        /// Note: The \p location argument is ignored for this advice.
        /// - ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION: This advice sets the preferred location for the
        /// data to be the memory belonging to \p location. When::CUmemLocation::type is ::CU_MEM_LOCATION_TYPE_HOST,
        /// ::CUmemLocation::id is ignored and the preferred location is set to be host memory.To set the preferred location
        /// to a specific host NUMA node, applications must set::CUmemLocation::type to ::CU_MEM_LOCATION_TYPE_HOST_NUMA and
        /// ::CUmemLocation::id must specify the NUMA ID of the host NUMA node.If ::CUmemLocation::type is set to ::CU_MEM_LOCATION_TYPE_HOST_NUMA_CURRENT,
        /// ::CUmemLocation::id will be ignored and the the host NUMA node closest to the calling thread's CPU will be used as the preferred location.
        /// If::CUmemLocation::type is a::CU_MEM_LOCATION_TYPE_DEVICE, then::CUmemLocation::id must be a valid device ordinal
        /// and the device must have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
        /// Setting the preferred location does not cause data to migrate to that location immediately.Instead, it guides the migration policy
        /// when a fault occurs on that memory region.If the data is already in its preferred location and the
        /// faulting processor can establish a mapping without requiring the data to be migrated, then
        /// data migration will be avoided. On the other hand, if the data is not in its preferred location
        /// or if a direct mapping cannot be established, then it will be migrated to the processor accessing
        /// it. It is important to note that setting the preferred location does not prevent data prefetching
        /// done using ::cuMemPrefetchAsync.
        /// Having a preferred location can override the page thrash detection and resolution logic in the Unified
        /// Memory driver.Normally, if a page is detected to be constantly thrashing between for example host and device
        /// memory, the page may eventually be pinned to host memory by the Unified Memory driver.But
        /// if the preferred location is set as device memory, then the page will continue to thrash indefinitely.
        /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
        /// policies associated with that advice will override the policies of this advice, unless read accesses from
        /// \p location will not result in a read-only copy being created on that procesor as outlined in description for
        /// the advice ::CU_MEM_ADVISE_SET_READ_MOSTLY.
        /// If the memory region refers to valid system-allocated pageable memory, and::CUmemLocation::type is CU_MEM_LOCATION_TYPE_DEVICE
        /// then ::CUmemLocation::id must be a valid device that has a non-zero alue for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
        /// - ::CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: Undoes the effect of ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION
        /// and changes the preferred location to none. The \p location argument is ignored for this advice.
        /// - ::CU_MEM_ADVISE_SET_ACCESSED_BY: This advice implies that the data will be accessed by processor \p location.
        /// The::CUmemLocation::type must be either ::CU_MEM_LOCATION_TYPE_DEVICE with ::CUmemLocation::id representing a valid device
        /// ordinal or::CU_MEM_LOCATION_TYPE_HOST and ::CUmemLocation::id will be ignored. All other location types are invalid.
        /// If::CUmemLocation::id is a GPU, then the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS must be non-zero.
        /// This advice does not cause data migration and has no impact on the location of the data per se. Instead,
        /// it causes the data to always be mapped in the specified processor's page tables, as long as the
        /// location of the data permits a mapping to be established. If the data gets migrated for any reason,
        /// the mappings are updated accordingly.
        /// This advice is recommended in scenarios where data locality is not important, but avoiding faults is.
        /// Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the
        /// data located on one GPU is occasionally accessed by peer GPUs.In such scenarios, migrating data
        /// over to the other GPUs is not as important because the accesses are infrequent and the overhead of
        /// migration may be too high.But preventing faults can still help improve performance, and so having
        /// a mapping set up in advance is useful.Note that on CPU access of this data, the data may be migrated
        /// to host memory because the CPU typically cannot access device memory directly.Any GPU that had the
        /// ::CU_MEM_ADVISE_SET_ACCESSED_BY flag set for this data will now have its mapping updated to point to the
        /// page in host memory.
        /// If::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
        /// policies associated with that advice will override the policies of this advice.Additionally, if the
        /// preferred location of this memory region or any subset of it is also \p location, then the policies
        /// associated with::CU_MEM_ADVISE_SET_PREFERRED_LOCATION will override the policies of this advice.
        /// If the memory region refers to valid system-allocated pageable memory, and::CUmemLocation::type is ::CU_MEM_LOCATION_TYPE_DEVICE
        /// then device in ::CUmemLocation::id must have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
        /// Additionally, if ::CUmemLocation::id has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
        /// then this call has no effect.
        /// - ::CU_MEM_ADVISE_UNSET_ACCESSED_BY: Undoes the effect of ::CU_MEM_ADVISE_SET_ACCESSED_BY.Any mappings to
        /// the data from \p location may be removed at any time causing accesses to result in non-fatal page faults.
        /// If the memory region refers to valid system-allocated pageable memory, and::CUmemLocation::type is ::CU_MEM_LOCATION_TYPE_DEVICE
        /// then device in ::CUmemLocation::id must have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
        /// Additionally, if ::CUmemLocation::id has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
        /// then this call has no effect.
        /// <para/>
        /// Note that this function is asynchronous with respect to the host and all work
        /// on other devices.
        /// </summary>
        /// <param name="devPtr">Pointer to memory to set the advice for</param>
		/// <param name="count">Size in bytes of the memory range</param>
        /// <param name="advice">Advice to be applied for the specified memory range</param>
        /// <param name="location">location to apply the advice for</param>
        /// <returns></returns>
		public static void MemAdvise(CUdeviceptr devPtr, SizeT count, CUmemAdvise advice, CUmemLocation location)
		{
			CUResult res = DriverAPINativeMethods.MemoryManagement.cuMemAdvise_v2(devPtr, count, advice, location);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemAdvise_v2", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}
		
        /// <summary>
        /// Advise about the usage of a given memory range<para/>
        /// Advise the Unified Memory subsystem about the usage pattern for the memory range
        /// starting at \p devPtr with a size of \p count bytes.The start address and end address of the memory
        /// range will be rounded down and rounded up respectively to be aligned to CPU page size before the
        /// advice is applied.The memory range must refer to managed memory allocated via ::cuMemAllocManaged
        /// or declared via __managed__ variables.The memory range could also refer to system-allocated pageable
        /// memory provided it represents a valid, host-accessible region of memory and all additional constraints
        /// imposed by \p advice as outlined below are also satisfied.Specifying an invalid system-allocated pageable
        /// memory range results in an error being returned.
        /// 
        /// The \p advice parameter can take the following values:
        /// - ::CU_MEM_ADVISE_SET_READ_MOSTLY: This implies that the data is mostly going to be read
        /// from and only occasionally written to.Any read accesses from any processor to this region will create a
        /// read-only copy of at least the accessed pages in that processor's memory. Additionally, if ::cuMemPrefetchAsync
        /// or::cuMemPrefetchAsync_v2 is called on this region, it will create a read-only copy of the data on the destination processor.
        /// If the target location for ::cuMemPrefetchAsync_v2 is a host NUMA node and a read-only copy already exists on
        /// another host NUMA node, that copy will be migrated to the targeted host NUMA node.
        /// If any processor writes to this region, all copies of the corresponding page will be invalidated
        /// except for the one where the write occurred. If the writing processor is the CPU and the preferred location of
        /// the page is a host NUMA node, then the page will also be migrated to that host NUMA node. The \p location argument is ignored for this advice.
        /// Note that for a page to be read-duplicated, the accessing processor must either be the CPU or a GPU
        /// that has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
        /// Also, if a context is created on a device that does not have the device attribute
        /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS set, then read-duplication will not occur until
        /// all such contexts are destroyed.
        /// If the memory region refers to valid system-allocated pageable memory, then the accessing device must
        /// have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS for a read-only
        /// copy to be created on that device. Note however that if the accessing device also has a non-zero value for the
        /// device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES, then setting this advice
        /// will not create a read-only copy when that device accesses this memory region.
        /// - ::CU_MEM_ADVISE_UNSET_READ_MOSTLY:  Undoes the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY and also prevents the
        /// Unified Memory driver from attempting heuristic read-duplication on the memory range.Any read-duplicated
        /// copies of the data will be collapsed into a single copy. The location for the collapsed
        /// copy will be the preferred location if the page has a preferred location and one of the read-duplicated
        /// copies was resident at that location.Otherwise, the location chosen is arbitrary.
        /// Note: The \p location argument is ignored for this advice.
        /// - ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION: This advice sets the preferred location for the
        /// data to be the memory belonging to \p location. When::CUmemLocation::type is ::CU_MEM_LOCATION_TYPE_HOST,
        /// ::CUmemLocation::id is ignored and the preferred location is set to be host memory.To set the preferred location
        /// to a specific host NUMA node, applications must set::CUmemLocation::type to ::CU_MEM_LOCATION_TYPE_HOST_NUMA and
        /// ::CUmemLocation::id must specify the NUMA ID of the host NUMA node.If ::CUmemLocation::type is set to ::CU_MEM_LOCATION_TYPE_HOST_NUMA_CURRENT,
        /// ::CUmemLocation::id will be ignored and the the host NUMA node closest to the calling thread's CPU will be used as the preferred location.
        /// If::CUmemLocation::type is a::CU_MEM_LOCATION_TYPE_DEVICE, then::CUmemLocation::id must be a valid device ordinal
        /// and the device must have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
        /// Setting the preferred location does not cause data to migrate to that location immediately.Instead, it guides the migration policy
        /// when a fault occurs on that memory region.If the data is already in its preferred location and the
        /// faulting processor can establish a mapping without requiring the data to be migrated, then
        /// data migration will be avoided. On the other hand, if the data is not in its preferred location
        /// or if a direct mapping cannot be established, then it will be migrated to the processor accessing
        /// it. It is important to note that setting the preferred location does not prevent data prefetching
        /// done using ::cuMemPrefetchAsync.
        /// Having a preferred location can override the page thrash detection and resolution logic in the Unified
        /// Memory driver.Normally, if a page is detected to be constantly thrashing between for example host and device
        /// memory, the page may eventually be pinned to host memory by the Unified Memory driver.But
        /// if the preferred location is set as device memory, then the page will continue to thrash indefinitely.
        /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
        /// policies associated with that advice will override the policies of this advice, unless read accesses from
        /// \p location will not result in a read-only copy being created on that procesor as outlined in description for
        /// the advice ::CU_MEM_ADVISE_SET_READ_MOSTLY.
        /// If the memory region refers to valid system-allocated pageable memory, and::CUmemLocation::type is CU_MEM_LOCATION_TYPE_DEVICE
        /// then ::CUmemLocation::id must be a valid device that has a non-zero alue for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
        /// - ::CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: Undoes the effect of ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION
        /// and changes the preferred location to none. The \p location argument is ignored for this advice.
        /// - ::CU_MEM_ADVISE_SET_ACCESSED_BY: This advice implies that the data will be accessed by processor \p location.
        /// The::CUmemLocation::type must be either ::CU_MEM_LOCATION_TYPE_DEVICE with ::CUmemLocation::id representing a valid device
        /// ordinal or::CU_MEM_LOCATION_TYPE_HOST and ::CUmemLocation::id will be ignored. All other location types are invalid.
        /// If::CUmemLocation::id is a GPU, then the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS must be non-zero.
        /// This advice does not cause data migration and has no impact on the location of the data per se. Instead,
        /// it causes the data to always be mapped in the specified processor's page tables, as long as the
        /// location of the data permits a mapping to be established. If the data gets migrated for any reason,
        /// the mappings are updated accordingly.
        /// This advice is recommended in scenarios where data locality is not important, but avoiding faults is.
        /// Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the
        /// data located on one GPU is occasionally accessed by peer GPUs.In such scenarios, migrating data
        /// over to the other GPUs is not as important because the accesses are infrequent and the overhead of
        /// migration may be too high.But preventing faults can still help improve performance, and so having
        /// a mapping set up in advance is useful.Note that on CPU access of this data, the data may be migrated
        /// to host memory because the CPU typically cannot access device memory directly.Any GPU that had the
        /// ::CU_MEM_ADVISE_SET_ACCESSED_BY flag set for this data will now have its mapping updated to point to the
        /// page in host memory.
        /// If::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
        /// policies associated with that advice will override the policies of this advice.Additionally, if the
        /// preferred location of this memory region or any subset of it is also \p location, then the policies
        /// associated with::CU_MEM_ADVISE_SET_PREFERRED_LOCATION will override the policies of this advice.
        /// If the memory region refers to valid system-allocated pageable memory, and::CUmemLocation::type is ::CU_MEM_LOCATION_TYPE_DEVICE
        /// then device in ::CUmemLocation::id must have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
        /// Additionally, if ::CUmemLocation::id has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
        /// then this call has no effect.
        /// - ::CU_MEM_ADVISE_UNSET_ACCESSED_BY: Undoes the effect of ::CU_MEM_ADVISE_SET_ACCESSED_BY.Any mappings to
        /// the data from \p location may be removed at any time causing accesses to result in non-fatal page faults.
        /// If the memory region refers to valid system-allocated pageable memory, and::CUmemLocation::type is ::CU_MEM_LOCATION_TYPE_DEVICE
        /// then device in ::CUmemLocation::id must have a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
        /// Additionally, if ::CUmemLocation::id has a non-zero value for the device attribute::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
        /// then this call has no effect.
        /// <para/>
        /// Note that this function is asynchronous with respect to the host and all work
        /// on other devices.
        /// </summary>
        /// <param name="devPtr">Pointer to memory to set the advice for</param>
        /// <param name="advice">Advice to be applied for the specified memory range</param>
        /// <param name="location">location to apply the advice for</param>
        /// <returns></returns>
		public static void MemAdvise(CudaManagedMemory_<#=type#> devPtr, CUmemAdvise advice, CUmemLocation location)
		{
			CUResult res = DriverAPINativeMethods.MemoryManagement.cuMemAdvise_v2(devPtr.DevicePointer, devPtr.SizeInBytes, advice, location);
			Debug.WriteLine(String.Format("{0:G}, {1}: {2}", DateTime.Now, "cuMemAdvise_v2", res));
			if (res != CUResult.Success) throw new CudaException(res);
		}
	}
	
	/// <summary>
	/// Enumerator class for CudaManagedMemory_<#=type#>
	/// </summary>
	public class CudaManagedMemoryEnumerator_<#=type#> : IEnumerator<<#=type#>>
	{
		private CudaManagedMemory_<#=type#> _memory = null;
		private SizeT _currentIndex = -1;

		/// <summary>
		/// 
		/// </summary>
		/// <param name="memory"></param>
		public CudaManagedMemoryEnumerator_<#=type#>(CudaManagedMemory_<#=type#> memory)
		{
			_memory = memory;
		}

		void IDisposable.Dispose() { }

		/// <summary>
		/// 
		/// </summary>
		public void Reset()
		{
			_currentIndex = -1;
		}

		/// <summary>
		/// 
		/// </summary>
		public <#=type#> Current
		{
			get { return _memory[_currentIndex]; }
		}

		/// <summary>
		/// 
		/// </summary>
		object IEnumerator.Current
		{
			get { return _memory[_currentIndex]; }
		}

		/// <summary>
		/// 
		/// </summary>
		/// <returns></returns>
		public bool MoveNext()
		{
			_currentIndex += 1;
			if ((long)_currentIndex >= (long)_memory.Size)
				return false;
			else
				return true;
		}

	}

	<#}#>

}
